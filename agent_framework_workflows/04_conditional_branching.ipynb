{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6021b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Literal\n",
    "from uuid import uuid4\n",
    "\n",
    "from typing_extensions import Never\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    executor,\n",
    "    Case,\n",
    "    Default,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9a4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionResult(BaseModel):\n",
    "    \"\"\"Represents the result of spam detection.\"\"\"\n",
    "    # is_spam drives the routing decision taken by edge conditions\n",
    "    is_spam: bool\n",
    "    # Human readable rationale from the detector\n",
    "    reason: str\n",
    "    # The agent must include the original email so downstream agents can operate without reloading content\n",
    "    email_content: str\n",
    "\n",
    "\n",
    "class EmailResponse(BaseModel):\n",
    "    \"\"\"Represents the response from the email assistant.\"\"\"\n",
    "    # The drafted reply that a user could copy or send\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f216c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_condition(expected_result: bool):\n",
    "    \"\"\"Create a condition callable that routes based on DetectionResult.is_spam.\"\"\"\n",
    "\n",
    "    # The returned function will be used as an edge predicate.\n",
    "    # It receives whatever the upstream executor produced.\n",
    "    def condition(message: Any) -> bool:\n",
    "        # Defensive guard. If a non AgentExecutorResponse appears, let the edge pass to avoid dead ends.\n",
    "        if not isinstance(message, AgentExecutorResponse):\n",
    "            return True\n",
    "\n",
    "        try:\n",
    "            # Prefer parsing a structured DetectionResult from the agent JSON text.\n",
    "            # Using model_validate_json ensures type safety and raises if the shape is wrong.\n",
    "            detection = DetectionResult.model_validate_json(message.agent_run_response.text)\n",
    "            # Route only when the spam flag matches the expected path.\n",
    "            return detection.is_spam == expected_result\n",
    "        except Exception:\n",
    "            # Fail closed on parse errors so we do not accidentally route to the wrong path.\n",
    "            # Returning False prevents this edge from activating.\n",
    "            return False\n",
    "\n",
    "    return condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e1ccabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@executor(id=\"send_email\")\n",
    "async def handle_email_response(response: AgentExecutorResponse, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle legitimate emails by drafting a professional response.\"\"\"\n",
    "    # Downstream of the email assistant. Parse a validated EmailResponse and yield the workflow output.\n",
    "    email_response = EmailResponse.model_validate_json(response.agent_run_response.text)\n",
    "    await ctx.yield_output(f\"Email sent:\\n{email_response.response}\")\n",
    "\n",
    "\n",
    "@executor(id=\"handle_spam\")\n",
    "async def handle_spam_classifier_response(response: AgentExecutorResponse, ctx: WorkflowContext[Never, str]) -> None:\n",
    "    \"\"\"Handle spam emails by marking them appropriately.\"\"\"\n",
    "    # Spam path. Confirm the DetectionResult and yield the workflow output. Guard against accidental non spam input.\n",
    "    detection = DetectionResult.model_validate_json(response.agent_run_response.text)\n",
    "    if detection.is_spam:\n",
    "        await ctx.yield_output(f\"Email marked as spam: {detection.reason}\")\n",
    "    else:\n",
    "        # This indicates the routing predicate and executor contract are out of sync.\n",
    "        raise RuntimeError(\"This executor should only handle spam messages.\")\n",
    "\n",
    "\n",
    "@executor(id=\"to_email_assistant_request\")\n",
    "async def to_email_assistant_request(\n",
    "    response: AgentExecutorResponse, ctx: WorkflowContext[AgentExecutorRequest]\n",
    ") -> None:\n",
    "    \"\"\"Transform spam detection response into a request for the email assistant.\"\"\"\n",
    "    # Parse the detection result and extract the email content for the assistant\n",
    "    detection = DetectionResult.model_validate_json(response.agent_run_response.text)\n",
    "\n",
    "    # Create a new request for the email assistant with the original email content\n",
    "    request = AgentExecutorRequest(\n",
    "        messages=[ChatMessage(Role.USER, text=detection.email_content)],\n",
    "        should_respond=True\n",
    "    )\n",
    "    await ctx.send_message(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6039b99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "email = \"\"\"Hi,\n",
    "\n",
    "Input needed for quarter report. Please send me the data.\n",
    "\n",
    "Thanks\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e19b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow output: Email sent:\n",
      "Hi,\n",
      "\n",
      "Thank you for your email. I will compile the necessary data and send it to you shortly to assist with the quarterly report. Please let me know if there's anything specific you'd like me to include or focus on.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "async def main() -> None:\n",
    "    # Create agents\n",
    "    # AzureCliCredential uses your current az login. This avoids embedding secrets in code.\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "\n",
    "    # Agent 1. Classifies spam and returns a DetectionResult object.\n",
    "    # response_format enforces that the LLM returns parsable JSON for the Pydantic model.\n",
    "    spam_detection_agent = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are a spam detection assistant that identifies spam emails. \"\n",
    "                \"Always return JSON with fields is_spam (bool), reason (string), and email_content (string). \"\n",
    "                \"Include the original email content in email_content.\"\n",
    "            ),\n",
    "            response_format=DetectionResult,\n",
    "        ),\n",
    "        id=\"spam_detection_agent\",\n",
    "    )\n",
    "\n",
    "    # Agent 2. Drafts a professional reply. Also uses structured JSON output for reliability.\n",
    "    email_assistant_agent = AgentExecutor(\n",
    "        chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an email assistant that helps users draft professional responses to emails. \"\n",
    "                \"Your input might be a JSON object that includes 'email_content'; base your reply on that content. \"\n",
    "                \"Return JSON with a single field 'response' containing the drafted reply.\"\n",
    "            ),\n",
    "            response_format=EmailResponse,\n",
    "        ),\n",
    "        id=\"email_assistant_agent\",\n",
    "    )\n",
    "\n",
    "    # Build the workflow graph.\n",
    "    # Start at the spam detector.\n",
    "    # If not spam, hop to a transformer that creates a new AgentExecutorRequest,\n",
    "    # then call the email assistant, then finalize.\n",
    "    # If spam, go directly to the spam handler and finalize.\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(spam_detection_agent)\n",
    "        # Not spam path: transform response -> request for assistant -> assistant -> send email\n",
    "        .add_edge(spam_detection_agent, to_email_assistant_request, condition=get_condition(False))\n",
    "        .add_edge(to_email_assistant_request, email_assistant_agent)\n",
    "        .add_edge(email_assistant_agent, handle_email_response)\n",
    "        # Spam path: send to spam handler\n",
    "        .add_edge(spam_detection_agent, handle_spam_classifier_response, condition=get_condition(True))\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Read Email content from the sample resource file.\n",
    "    # This keeps the sample deterministic since the model sees the same email every run.\n",
    "    #email_path = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), \"resources\", \"email.txt\")\n",
    "\n",
    "    # with open(email_path) as email_file:  # noqa: ASYNC230\n",
    "    #     email = email_file.read()\n",
    "\n",
    "    # Execute the workflow. Since the start is an AgentExecutor, pass an AgentExecutorRequest.\n",
    "    # The workflow completes when it becomes idle (no more work to do).\n",
    "    request = AgentExecutorRequest(messages=[ChatMessage(Role.USER, text=email)], should_respond=True)\n",
    "    events = await workflow.run(request)\n",
    "    outputs = events.get_outputs()\n",
    "    if outputs:\n",
    "        print(f\"Workflow output: {outputs[0]}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "070d696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_condition.<locals>.condition at 0x0000017BD2163920>\n"
     ]
    }
   ],
   "source": [
    "print(get_condition(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d052760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function get_condition.<locals>.condition at 0x0000017BD4F80360>\n"
     ]
    }
   ],
   "source": [
    "print(get_condition(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efba785c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
