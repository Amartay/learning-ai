{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "633f7a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentExecutor,\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    RequestInfoEvent,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "@dataclass\n",
    "class HumanFeedbackRequest(RequestInfoMessage):\n",
    "    \"\"\"Request message for human feedback in the guessing game.\"\"\"\n",
    "    prompt: str = \"\"\n",
    "    guess: int | None = None\n",
    "\n",
    "class GuessOutput(BaseModel):\n",
    "    \"\"\"Structured output from the AI agent with response_format enforcement.\"\"\"\n",
    "    guess: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92ac7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurnManager(Executor):\n",
    "    \"\"\"Coordinates turns between the AI agent and human player.\n",
    "\n",
    "    Responsibilities:\n",
    "    - Start the game by requesting the agent's first guess\n",
    "    - Process agent responses and request human feedback\n",
    "    - Handle human feedback and continue the game or finish\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id: str | None = None):\n",
    "        super().__init__(id=id or \"turn_manager\")\n",
    "\n",
    "    @handler\n",
    "    async def start(self, _: str, ctx: WorkflowContext[AgentExecutorRequest]) -> None:\n",
    "        \"\"\"Start the game by asking the agent for an initial guess.\"\"\"\n",
    "        user = ChatMessage(Role.USER, text=\"Start by making your first guess.\")\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user], should_respond=True))\n",
    "\n",
    "    @handler\n",
    "    async def on_agent_response(\n",
    "        self,\n",
    "        result: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[HumanFeedbackRequest],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle the agent's guess and request human guidance.\"\"\"\n",
    "        # Parse structured model output (defensive default if agent didn't reply)\n",
    "        text = result.agent_run_response.text or \"\"\n",
    "        last_guess = GuessOutput.model_validate_json(text).guess if text else None\n",
    "\n",
    "        # Craft a clear human prompt that defines higher/lower relative to agent's guess\n",
    "        prompt = (\n",
    "            f\"The agent guessed: {last_guess if last_guess is not None else text}. \"\n",
    "            \"Type one of: higher (your number is higher than this guess), \"\n",
    "            \"lower (your number is lower than this guess), correct, or exit.\"\n",
    "        )\n",
    "        await ctx.send_message(HumanFeedbackRequest(prompt=prompt, guess=last_guess))\n",
    "\n",
    "    @handler\n",
    "    async def on_human_feedback(\n",
    "        self,\n",
    "        feedback: RequestResponse[HumanFeedbackRequest, str],\n",
    "        ctx: WorkflowContext[AgentExecutorRequest, str],\n",
    "    ) -> None:\n",
    "        \"\"\"Continue the game or finish based on human feedback.\"\"\"\n",
    "        reply = (feedback.data or \"\").strip().lower()\n",
    "        # Use the correlated request's guess to avoid extra state reads\n",
    "        last_guess = getattr(feedback.original_request, \"guess\", None)\n",
    "\n",
    "        if reply == \"correct\":\n",
    "            await ctx.yield_output(f\"Guessed correctly: {last_guess}\")\n",
    "            return\n",
    "\n",
    "        # Provide feedback to the agent for the next guess\n",
    "        user_msg = ChatMessage(\n",
    "            Role.USER,\n",
    "            text=f'Feedback: {reply}. Return ONLY a JSON object matching the schema {{\"guess\": <int 1..10>}}.',\n",
    "        )\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=[user_msg], should_respond=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ab7acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    # Create the chat agent with structured output enforcement\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "    agent = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You guess a number between 1 and 10. \"\n",
    "            \"If the user says 'higher' or 'lower', adjust your next guess. \"\n",
    "            'You MUST return ONLY a JSON object exactly matching this schema: {\"guess\": <integer 1..10>}. '\n",
    "            \"No explanations or additional text.\"\n",
    "        ),\n",
    "        response_format=GuessOutput,\n",
    "    )\n",
    "\n",
    "    # Create workflow components\n",
    "    turn_manager = TurnManager(id=\"turn_manager\")\n",
    "    agent_exec = AgentExecutor(agent=agent, id=\"agent\")\n",
    "    request_info_executor = RequestInfoExecutor(id=\"request_info\")\n",
    "\n",
    "    # Build the workflow graph\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(turn_manager)\n",
    "        .add_edge(turn_manager, agent_exec)  # Ask agent to make/adjust a guess\n",
    "        .add_edge(agent_exec, turn_manager)  # Agent's response goes back to coordinator\n",
    "        .add_edge(turn_manager, request_info_executor)  # Ask human for guidance\n",
    "        .add_edge(request_info_executor, turn_manager)  # Feed human guidance back to coordinator\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Execute the interactive workflow\n",
    "    await run_interactive_workflow(workflow)\n",
    "\n",
    "async def run_interactive_workflow(workflow):\n",
    "    \"\"\"Run the workflow with human-in-the-loop interaction.\"\"\"\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed = False\n",
    "    workflow_output: str | None = None\n",
    "\n",
    "    print(\" Number Guessing Game\")\n",
    "    print(\"Think of a number between 1 and 10, and I'll try to guess it!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while not completed:\n",
    "        # First iteration uses run_stream(\"start\")\n",
    "        # Subsequent iterations use send_responses_streaming with pending responses\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses)\n",
    "            if pending_responses\n",
    "            else workflow.run_stream(\"start\")\n",
    "        )\n",
    "\n",
    "        # Collect events for this turn\n",
    "        events = [event async for event in stream]\n",
    "        pending_responses = None\n",
    "\n",
    "        # Process events to collect requests and detect completion\n",
    "        requests: list[tuple[str, str]] = []  # (request_id, prompt)\n",
    "        for event in events:\n",
    "            if isinstance(event, RequestInfoEvent) and isinstance(event.data, HumanFeedbackRequest):\n",
    "                # RequestInfoEvent for our HumanFeedbackRequest\n",
    "                requests.append((event.request_id, event.data.prompt))\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                # Capture workflow output when yielded\n",
    "                workflow_output = str(event.data)\n",
    "                completed = True\n",
    "\n",
    "        # Check workflow status\n",
    "        pending_status = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "        idle_with_requests = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "\n",
    "        if pending_status:\n",
    "            print(\" State: IN_PROGRESS_PENDING_REQUESTS (requests outstanding)\")\n",
    "        if idle_with_requests:\n",
    "            print(\"革  State: IDLE_WITH_PENDING_REQUESTS (awaiting human input)\")\n",
    "\n",
    "        # Handle human requests if any\n",
    "        if requests and not completed:\n",
    "            responses: dict[str, str] = {}\n",
    "            for req_id, prompt in requests:\n",
    "                print(f\"\\n {prompt}\")\n",
    "                answer = input(\" Enter higher/lower/correct/exit: \").lower()\n",
    "\n",
    "                if answer == \"exit\":\n",
    "                    print(\" Exiting...\")\n",
    "                    return\n",
    "                responses[req_id] = answer\n",
    "            pending_responses = responses\n",
    "\n",
    "    # Show final result\n",
    "    print(f\"\\n {workflow_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd842ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main() -> None:\n",
    "    # Create the chat agent with structured output enforcement\n",
    "    chat_client = AzureOpenAIChatClient(credential=AzureCliCredential())\n",
    "    agent = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You guess a number between 1 and 10. \"\n",
    "            \"If the user says 'higher' or 'lower', adjust your next guess. \"\n",
    "            'You MUST return ONLY a JSON object exactly matching this schema: {\"guess\": <integer 1..10>}. '\n",
    "            \"No explanations or additional text.\"\n",
    "        ),\n",
    "        response_format=GuessOutput,\n",
    "    )\n",
    "\n",
    "    # Create workflow components\n",
    "    turn_manager = TurnManager(id=\"turn_manager\")\n",
    "    agent_exec = AgentExecutor(agent=agent, id=\"agent\")\n",
    "    request_info_executor = RequestInfoExecutor(id=\"request_info\")\n",
    "\n",
    "    # Build the workflow graph\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .set_start_executor(turn_manager)\n",
    "        .add_edge(turn_manager, agent_exec)  # Ask agent to make/adjust a guess\n",
    "        .add_edge(agent_exec, turn_manager)  # Agent's response goes back to coordinator\n",
    "        .add_edge(turn_manager, request_info_executor)  # Ask human for guidance\n",
    "        .add_edge(request_info_executor, turn_manager)  # Feed human guidance back to coordinator\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    # Execute the interactive workflow\n",
    "    await run_interactive_workflow(workflow)\n",
    "\n",
    "async def run_interactive_workflow(workflow):\n",
    "    \"\"\"Run the workflow with human-in-the-loop interaction.\"\"\"\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed = False\n",
    "    workflow_output: str | None = None\n",
    "\n",
    "    print(\" Number Guessing Game\")\n",
    "    print(\"Think of a number between 1 and 10, and I'll try to guess it!\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    while not completed:\n",
    "        # First iteration uses run_stream(\"start\")\n",
    "        # Subsequent iterations use send_responses_streaming with pending responses\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses)\n",
    "            if pending_responses\n",
    "            else workflow.run_stream(\"start\")\n",
    "        )\n",
    "\n",
    "        # Collect events for this turn\n",
    "        events = [event async for event in stream]\n",
    "        pending_responses = None\n",
    "\n",
    "        # Process events to collect requests and detect completion\n",
    "        requests: list[tuple[str, str]] = []  # (request_id, prompt)\n",
    "        for event in events:\n",
    "            if isinstance(event, RequestInfoEvent) and isinstance(event.data, HumanFeedbackRequest):\n",
    "                # RequestInfoEvent for our HumanFeedbackRequest\n",
    "                requests.append((event.request_id, event.data.prompt))\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                # Capture workflow output when yielded\n",
    "                workflow_output = str(event.data)\n",
    "                completed = True\n",
    "\n",
    "        # Check workflow status\n",
    "        pending_status = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "        idle_with_requests = any(\n",
    "            isinstance(e, WorkflowStatusEvent) and e.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS\n",
    "            for e in events\n",
    "        )\n",
    "\n",
    "        if pending_status:\n",
    "            print(\" State: IN_PROGRESS_PENDING_REQUESTS (requests outstanding)\")\n",
    "        if idle_with_requests:\n",
    "            print(\"革  State: IDLE_WITH_PENDING_REQUESTS (awaiting human input)\")\n",
    "\n",
    "        # Handle human requests if any\n",
    "        if requests and not completed:\n",
    "            responses: dict[str, str] = {}\n",
    "            for req_id, prompt in requests:\n",
    "                print(f\"\\n {prompt}\")\n",
    "                answer = input(\" Enter higher/lower/correct/exit: \").lower()\n",
    "\n",
    "                if answer == \"exit\":\n",
    "                    print(\" Exiting...\")\n",
    "                    return\n",
    "                responses[req_id] = answer\n",
    "            pending_responses = responses\n",
    "\n",
    "    # Show final result\n",
    "    print(f\"\\n {workflow_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a732c3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-17 10:50:20 - c:\\Users\\amartays\\env\\Lib\\site-packages\\agent_framework\\_workflows\\_validation.py:520 - WARNING] Cycle detected in the workflow graph involving: request_info -> agent -> turn_manager -> request_info. Ensure termination or iteration limits exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number Guessing Game\n",
      "Think of a number between 1 and 10, and I'll try to guess it!\n",
      "--------------------------------------------------\n",
      " State: IN_PROGRESS_PENDING_REQUESTS (requests outstanding)\n",
      "革  State: IDLE_WITH_PENDING_REQUESTS (awaiting human input)\n",
      "\n",
      " The agent guessed: 5. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
      " State: IN_PROGRESS_PENDING_REQUESTS (requests outstanding)\n",
      "革  State: IDLE_WITH_PENDING_REQUESTS (awaiting human input)\n",
      "\n",
      " The agent guessed: 3. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
      " State: IN_PROGRESS_PENDING_REQUESTS (requests outstanding)\n",
      "革  State: IDLE_WITH_PENDING_REQUESTS (awaiting human input)\n",
      "\n",
      " The agent guessed: 4. Type one of: higher (your number is higher than this guess), lower (your number is lower than this guess), correct, or exit.\n",
      "\n",
      " Guessed correctly: 4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7633f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
